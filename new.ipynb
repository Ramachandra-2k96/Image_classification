{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "LightweightMedicalCNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (spatial_attention): Sequential(\n",
      "    (0): Conv2d(128, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (caps_layer): Sequential(\n",
      "    (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AdaptiveAvgPool2d(output_size=(4, 4))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total Parameters: 184,918\n",
      "Trainable Parameters: 184,918\n",
      "Estimated Model Size: 0.71 MB\n",
      "\n",
      "Input Shape: (1, 1, 256, 256)\n",
      "Output Shape: torch.Size([1, 5])\n",
      "\n",
      "Model summary test passed successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import torchsummary\n",
    "import numpy as np\n",
    "\n",
    "class LightweightMedicalCNN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=1):\n",
    "        super(LightweightMedicalCNN, self).__init__()\n",
    "        \n",
    "        # Initial parameters\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # Second Convolutional Block with Primary Caps inspiration\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # Spatial Attention Module\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(128, 1, kernel_size=7, padding=3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Dynamic Routing inspired module\n",
    "        self.caps_layer = nn.Sequential(\n",
    "            nn.Conv2d(128, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4, 4))\n",
    "        )\n",
    "        \n",
    "        # Calculate the size for the flatten layer\n",
    "        self._to_linear = 16 * 4 * 4\n",
    "        \n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self._to_linear, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Second block\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # Third block\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Apply spatial attention\n",
    "        attention = self.spatial_attention(x)\n",
    "        x = x * attention\n",
    "        \n",
    "        # Capsule inspired feature extraction\n",
    "        x = self.caps_layer(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def print_model_summary(model, input_size=(1, 256, 256)):\n",
    "    \"\"\"\n",
    "    Print model summary and calculate model size\n",
    "    \"\"\"\n",
    "    # Convert input size to include batch dimension\n",
    "    batch_size = 1\n",
    "    input_shape = (batch_size, *input_size)\n",
    "    \n",
    "    # Create dummy input\n",
    "    dummy_input = torch.randn(input_shape)\n",
    "    \n",
    "    # Print model architecture\n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(model)\n",
    "    \n",
    "    # Calculate total parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Estimate model size in MB\n",
    "    model_size_mb = total_params * 4 / (1024 * 1024)  # Assuming 4 bytes per parameter\n",
    "    print(f\"Estimated Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    try:\n",
    "        output = model(dummy_input)\n",
    "        print(f\"\\nInput Shape: {input_shape}\")\n",
    "        print(f\"Output Shape: {output.shape}\")\n",
    "        print(\"\\nModel summary test passed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during forward pass: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "def test_model(num_classes=5):\n",
    "    \"\"\"\n",
    "    Test the model with sample data\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model = LightweightMedicalCNN(num_classes=num_classes, in_channels=1)\n",
    "    \n",
    "    # Print model summary\n",
    "    print_model_summary(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with 5 classes\n",
    "    model = test_model(num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class SquashFunction(nn.Module):\n",
    "    def forward(self, x, dim=-1):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / torch.sqrt(squared_norm + 1e-8)\n",
    "\n",
    "class PrimaryCapsules(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dim_caps, kernel_size, stride):\n",
    "        super(PrimaryCapsules, self).__init__()\n",
    "        self.dim_caps = dim_caps\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * dim_caps, kernel_size, stride, padding=1)  # Added padding=1\n",
    "        self.squash = SquashFunction()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.conv(x)\n",
    "        batch, _, height, width = outputs.shape\n",
    "        \n",
    "        outputs = outputs.view(batch, self.out_channels, self.dim_caps, height, width)\n",
    "        outputs = outputs.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        outputs = outputs.view(batch, -1, self.dim_caps)\n",
    "        \n",
    "        return self.squash(outputs)\n",
    "\n",
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_caps_in, num_caps_out, dim_caps_in, dim_caps_out, num_iterations=3):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_caps_in = num_caps_in\n",
    "        self.num_caps_out = num_caps_out\n",
    "        \n",
    "        self.W = nn.Parameter(torch.randn(1, num_caps_in, num_caps_out, dim_caps_out, dim_caps_in))\n",
    "        self.squash = SquashFunction()\n",
    "\n",
    "    def forward(self, u):\n",
    "        batch_size = u.size(0)\n",
    "        u = u.unsqueeze(2).unsqueeze(4)\n",
    "        u_hat = torch.matmul(self.W, u)\n",
    "        u_hat = u_hat.squeeze(-1)\n",
    "        \n",
    "        b = torch.zeros(batch_size, self.num_caps_in, self.num_caps_out).to(u.device)\n",
    "        \n",
    "        for i in range(self.num_iterations):\n",
    "            c = F.softmax(b, dim=2)\n",
    "            c = c.unsqueeze(3)\n",
    "            s = (c * u_hat).sum(dim=1)\n",
    "            v = self.squash(s)\n",
    "            if i < self.num_iterations - 1:\n",
    "                b = b + (u_hat * v.unsqueeze(1)).sum(dim=-1)\n",
    "        \n",
    "        return v\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_layers, growth_rate=12):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            layer = nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels + i * growth_rate),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels + i * growth_rate, growth_rate, kernel_size=3, padding=1),\n",
    "                nn.Dropout(0.2)\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            new_features = layer(torch.cat(features, 1))\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "class EnhancedMedicalCapsCNN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=1):\n",
    "        super(EnhancedMedicalCapsCNN, self).__init__()\n",
    "        \n",
    "        # Initial feature extraction (256x256 -> 64x64)\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Multi-scale feature extraction (64x64 -> 64x64)\n",
    "        self.multi_scale = nn.ModuleList([\n",
    "            nn.Conv2d(32, 16, kernel_size=k, padding=k//2) \n",
    "            for k in [3, 5, 7]\n",
    "        ])\n",
    "        \n",
    "        # Dense block (64x64 -> 64x64)\n",
    "        self.dense_block = DenseBlock(48, num_layers=4, growth_rate=12)\n",
    "        dense_out_channels = 48 + 4 * 12  # 96 channels\n",
    "        \n",
    "        # Transition layer (64x64 -> 32x32)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.BatchNorm2d(dense_out_channels),\n",
    "            nn.Conv2d(dense_out_channels, dense_out_channels // 2, kernel_size=1),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        transition_out_channels = dense_out_channels // 2  # 48 channels\n",
    "        \n",
    "        # Primary capsules (32x32 -> 16x16 with padding=1)\n",
    "        self.primary_caps = PrimaryCapsules(\n",
    "            in_channels=transition_out_channels,\n",
    "            out_channels=32,\n",
    "            dim_caps=8,\n",
    "            kernel_size=3,\n",
    "            stride=2\n",
    "        )\n",
    "        \n",
    "        # Calculate primary capsules output size\n",
    "        # After PrimaryCapsules: 16x16 feature maps with 32 channels\n",
    "        # Total capsules = 32 * 16 * 16 = 8192\n",
    "        primary_caps_size = 32 * 16 * 16  # 8192\n",
    "        \n",
    "        # Medical feature capsules\n",
    "        self.medical_caps = CapsuleLayer(\n",
    "            num_caps_in=primary_caps_size,\n",
    "            num_caps_out=16,\n",
    "            dim_caps_in=8,\n",
    "            dim_caps_out=16\n",
    "        )\n",
    "        \n",
    "        # Diagnostic capsules\n",
    "        self.diagnostic_caps = CapsuleLayer(\n",
    "            num_caps_in=16,\n",
    "            num_caps_out=num_classes,\n",
    "            dim_caps_in=16,\n",
    "            dim_caps_out=16\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(48, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_classes * 16, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial feature extraction (256x256 -> 64x64)\n",
    "        x = self.init_conv(x)  # Output: [batch, 32, 64, 64]\n",
    "        \n",
    "        # Multi-scale feature extraction\n",
    "        multi_scale_features = [conv(x) for conv in self.multi_scale]\n",
    "        x = torch.cat(multi_scale_features, dim=1)  # Output: [batch, 48, 64, 64]\n",
    "        \n",
    "        # Apply attention\n",
    "        attention = self.attention(x)\n",
    "        x = x * attention\n",
    "        \n",
    "        # Dense feature extraction with transition (64x64 -> 32x32)\n",
    "        x = self.dense_block(x)  # Output: [batch, 96, 64, 64]\n",
    "        x = self.transition(x)   # Output: [batch, 48, 32, 32]\n",
    "        \n",
    "        # Primary capsules (32x32 -> 16x16)\n",
    "        primary_caps = self.primary_caps(x)  # Output: [batch, 8192, 8]\n",
    "        \n",
    "        # Medical feature capsules\n",
    "        medical_caps = self.medical_caps(primary_caps)  # Output: [batch, 16, 16]\n",
    "        \n",
    "        # Diagnostic capsules\n",
    "        diagnostic_caps = self.diagnostic_caps(medical_caps)  # Output: [batch, num_classes, 16]\n",
    "        \n",
    "        # Final classification\n",
    "        x = diagnostic_caps.view(diagnostic_caps.size(0), -1)\n",
    "        output = self.classifier(x)\n",
    "        \n",
    "        if self.training:\n",
    "            return output, diagnostic_caps\n",
    "        return output\n",
    "\n",
    "# The rest of the code remains the same\n",
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, m_pos=0.9, m_neg=0.1, lambda_=0.5):\n",
    "        super(MarginLoss, self).__init__()\n",
    "        self.m_pos = m_pos\n",
    "        self.m_neg = m_neg\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, caps_output, target):\n",
    "        batch_size = caps_output.size(0)\n",
    "        v_c = torch.sqrt((caps_output ** 2).sum(dim=-1))\n",
    "        \n",
    "        left = F.relu(self.m_pos - v_c) ** 2\n",
    "        right = F.relu(v_c - self.m_neg) ** 2\n",
    "        \n",
    "        target = F.one_hot(target, num_classes=v_c.size(1))\n",
    "        \n",
    "        loss = target * left + self.lambda_ * (1.0 - target) * right\n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "def print_model_summary(model, input_size=(1, 256, 256)):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    batch_size = 1\n",
    "    input_shape = (batch_size, *input_size)\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(model)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "    \n",
    "    model_size_mb = total_params * 4 / (1024 * 1024)\n",
    "    print(f\"Estimated Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    try:\n",
    "        output = model(dummy_input)\n",
    "        print(f\"\\nInput Shape: {input_shape}\")\n",
    "        if isinstance(output, tuple):\n",
    "            print(f\"Output Shapes: {[o.shape for o in output]}\")\n",
    "        else:\n",
    "            print(f\"Output Shape: {output.shape}\")\n",
    "        print(\"\\nModel summary test passed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during forward pass: {str(e)}\")\n",
    "\n",
    "def test_model(num_classes=5):\n",
    "    model = EnhancedMedicalCapsCNN(num_classes=num_classes)\n",
    "    print_model_summary(model)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = test_model(num_classes=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
