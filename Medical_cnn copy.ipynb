{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Edited 02/11/2024 \n",
    "Do not Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "        self.original_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    def apply_clahe(self, clip_limit=4.0, tile_grid_size=(1, 1)):\n",
    "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "        clahe_img = clahe.apply(self.original_img)\n",
    "        return clahe_img\n",
    "\n",
    "    def gamma_correction(self, image, gamma=0.9):\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        gamma_img = np.array(255 * (image / 255) ** inv_gamma, dtype='uint8')\n",
    "        return gamma_img\n",
    "\n",
    "    def unsharp_mask(self, image, strength=1.5, blur_size=(3, 3)):\n",
    "        blurred = cv2.GaussianBlur(image, blur_size, 0)\n",
    "        sharpened_img = cv2.addWeighted(image, 1 + strength, blurred, -strength, 0)\n",
    "        return sharpened_img\n",
    "\n",
    "    def gaussian_smoothing(self, image, kernel_size=(3, 3)):\n",
    "        smoothed_img = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "        return smoothed_img\n",
    "\n",
    "    def normalize_image(self, image):\n",
    "        normalized_img = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "        return normalized_img\n",
    "\n",
    "    def resize_image(self, image, target_size):\n",
    "        resized_img = np.array(Image.fromarray((image * 255).astype(np.uint8)).resize(target_size))\n",
    "        return resized_img\n",
    "\n",
    "    def process_and_display(self, resize=(256, 256)):\n",
    "        # Perform all preprocessing steps\n",
    "        clahe_img = self.apply_clahe()\n",
    "        gamma_img = self.gamma_correction(clahe_img)\n",
    "        sharpened_img = self.unsharp_mask(gamma_img)\n",
    "        smoothed_img = self.gaussian_smoothing(sharpened_img)\n",
    "        normalized_img = self.normalize_image(smoothed_img)\n",
    "        final_resized_img = self.resize_image(normalized_img, resize)\n",
    "\n",
    "        # Plot the images with headings\n",
    "        images = [self.original_img, clahe_img, gamma_img, sharpened_img, smoothed_img, final_resized_img]\n",
    "        titles = ['Original Image', 'CLAHE', 'Gamma Corrected', 'Unsharp Mask', 'Gaussian Smoothed', 'Final Resized']\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        for i, (img, title) in enumerate(zip(images, titles)):\n",
    "            plt.subplot(1, 6, i + 1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(title)\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        return final_resized_img\n",
    "\n",
    "# Usage\n",
    "image_path = 'DATASETS/split_data/train/0/9996086L.png'\n",
    "preprocessor = ImagePreprocessor(image_path)\n",
    "final_image = preprocessor.process_and_display((512, 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def process_dataset(dataset_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Count total files for progress bar\n",
    "    total_files = sum(len(files) for _, _, files in os.walk(dataset_dir))\n",
    "\n",
    "    with tqdm(total=total_files, unit=\"images\", desc=\"Preprocessing dataset\") as pbar:\n",
    "        for dirname, _, filenames in os.walk(dataset_dir):\n",
    "            \n",
    "            # Check if directory name is numeric, indicating a label folder\n",
    "            if os.path.basename(dirname).isdigit():\n",
    "                label = int(os.path.basename(dirname))  # Folder name as the label\n",
    "\n",
    "                for filename in filenames:\n",
    "                    image_path = os.path.join(dirname, filename)\n",
    "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                    # Initialize preprocessor with the image path\n",
    "                    preprocessor = ImagePreprocessor(image_path)\n",
    "                    clahe_img = preprocessor.apply_clahe()\n",
    "                    gamma_img = preprocessor.gamma_correction(clahe_img)\n",
    "                    sharpened_img = preprocessor.unsharp_mask(gamma_img)\n",
    "                    smoothed_img = preprocessor.gaussian_smoothing(sharpened_img)\n",
    "                    normalized_img = preprocessor.normalize_image(smoothed_img)\n",
    "                    final_resized_img = preprocessor.resize_image(normalized_img, (512, 512))\n",
    "\n",
    "                    X.append(final_resized_img)\n",
    "                    y.append(label)\n",
    "\n",
    "                    pbar.update(1)\n",
    "        # Convert lists to NumPy arrays first\n",
    "        X_array = np.array(X)  # Convert to NumPy array\n",
    "        y_array = np.array(y)\n",
    "        # Convert lists to PyTorch tensors\n",
    "        X_tensor = torch.tensor(X_array).float()  # Convert to float tensor\n",
    "        y_tensor = torch.tensor(y_array).long()   # Convert to long tensor for labels\n",
    "    return X_tensor, y_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dataset_dir =[\"DATASETS/kneeKL299/train/\",\"DATASETS/train/train/\",\"DATASETS/split_data/train/\"]#\"DATASETS/split_data/train/\",\"DATASETS/train/train/\"\n",
    "X_train, y_train = None, None\n",
    "\n",
    "for data in dataset_dir:\n",
    "    X_temp, y_temp = process_dataset(data)\n",
    "    if X_train is None:\n",
    "        X_train, y_train = X_temp, y_temp\n",
    "    X_train=torch.cat((X_train, X_temp), dim=0)\n",
    "    y_train=torch.cat((y_train, y_temp), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Usage\n",
    "# dataset_dir = \"DATASETS/kneeKL224/train/\"\n",
    "# X_train1, y_train1 = process_dataset(dataset_dir)\n",
    "# # Usage\n",
    "# dataset_dir2 = \"DATASETS/kneeKL299/train/\"\n",
    "# X_train2, y_train2 = process_dataset(dataset_dir2)\n",
    "# # Usage\n",
    "# dataset_dir3 = \"DATASETS/split_data/train/\"\n",
    "# X_train3, y_train3 = process_dataset(dataset_dir3)\n",
    "# # Usage\n",
    "# dataset_dir4 = \"DATASETS/train/train/\"\n",
    "# X_train4, y_train4 = process_dataset(dataset_dir4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Combine along a specific dimension (e.g., dimension 0)\n",
    "# X_train = torch.cat((X_train1, X_train2,X_train3,X_train4), dim=0)\n",
    "# y_train = torch.cat((y_train1, y_train2,y_train3,y_train4), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"DATASETS/OSAIL_KL_Dataset/Labeled/\"\n",
    "X_val, y_val = process_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"DATASETS/split_data/test/\"\n",
    "X_test, y_test = process_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot random images with labels to check preprocessing\n",
    "num_samples = 5\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(num_samples):\n",
    "    idx = np.random.randint(0, len(X_train))\n",
    "    plt.subplot(1, num_samples, i + 1)\n",
    "    plt.imshow(X_train[idx], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array\n",
    "y_train_np = y_train.numpy()\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = collections.Counter(y_train_np)\n",
    "\n",
    "# Print the label distribution\n",
    "print(\"Label distribution:\", label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [label_counts[i] for i in range(len(label_counts))]\n",
    "\n",
    "# Print the label list\n",
    "print(\"Label counts as list:\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torchsummary import torchsummary\n",
    "# import numpy as np\n",
    "\n",
    "# class LightweightMedicalCNN(nn.Module):\n",
    "#     def __init__(self, num_classes, in_channels=1):\n",
    "#         super(LightweightMedicalCNN, self).__init__()\n",
    "        \n",
    "#         # Initial parameters\n",
    "#         self.in_channels = in_channels\n",
    "#         self.num_classes = num_classes\n",
    "        \n",
    "#         # First Convolutional Block\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "        \n",
    "#         # Second Convolutional Block with Primary Caps inspiration\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "        \n",
    "#         # Third Convolutional Block\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2)\n",
    "#         )\n",
    "        \n",
    "#         # Spatial Attention Module\n",
    "#         self.spatial_attention = nn.Sequential(\n",
    "#             nn.Conv2d(128, 1, kernel_size=7, padding=3),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "        \n",
    "#         # Dynamic Routing inspired module\n",
    "#         self.caps_layer = nn.Sequential(\n",
    "#             nn.Conv2d(128, 16, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.AdaptiveAvgPool2d((4, 4))\n",
    "#         )\n",
    "        \n",
    "#         # Calculate the size for the flatten layer\n",
    "#         self._to_linear = 16 * 4 * 4\n",
    "        \n",
    "#         # Classification layers\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(self._to_linear, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(256, num_classes)\n",
    "#         )\n",
    "        \n",
    "#         # Initialize weights\n",
    "#         self._initialize_weights()\n",
    "        \n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                 if m.bias is not None:\n",
    "#                     nn.init.constant_(m.bias, 0)\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 nn.init.normal_(m.weight, 0, 0.01)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # First block\n",
    "#         x = self.conv1(x)\n",
    "        \n",
    "#         # Second block\n",
    "#         x = self.conv2(x)\n",
    "        \n",
    "#         # Third block\n",
    "#         x = self.conv3(x)\n",
    "        \n",
    "#         # Apply spatial attention\n",
    "#         attention = self.spatial_attention(x)\n",
    "#         x = x * attention\n",
    "        \n",
    "#         # Capsule inspired feature extraction\n",
    "#         x = self.caps_layer(x)\n",
    "        \n",
    "#         # Flatten\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Classification\n",
    "#         x = self.classifier(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# def print_model_summary(model, input_size=(1, 512, 512)):\n",
    "#     \"\"\"\n",
    "#     Print model summary and calculate model size\n",
    "#     \"\"\"\n",
    "#     # Convert input size to include batch dimension\n",
    "#     batch_size = 1\n",
    "#     input_shape = (batch_size, *input_size)\n",
    "    \n",
    "#     # Create dummy input\n",
    "#     dummy_input = torch.randn(input_shape)\n",
    "    \n",
    "#     # Print model architecture\n",
    "#     print(\"\\nModel Architecture:\")\n",
    "#     print(model)\n",
    "    \n",
    "#     # Calculate total parameters\n",
    "#     total_params = sum(p.numel() for p in model.parameters())\n",
    "#     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "#     print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "#     print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "    \n",
    "#     # Estimate model size in MB\n",
    "#     model_size_mb = total_params * 4 / (1024 * 1024)  # Assuming 4 bytes per parameter\n",
    "#     print(f\"Estimated Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "#     # Test forward pass\n",
    "#     try:\n",
    "#         output = model(dummy_input)\n",
    "#         print(f\"\\nInput Shape: {input_shape}\")\n",
    "#         print(f\"Output Shape: {output.shape}\")\n",
    "#         print(\"\\nModel summary test passed successfully!\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nError during forward pass: {str(e)}\")\n",
    "\n",
    "# # Example usage\n",
    "# def test_model(num_classes=5):\n",
    "#     \"\"\"\n",
    "#     Test the model with sample data\n",
    "#     \"\"\"\n",
    "#     # Initialize model\n",
    "#     model = LightweightMedicalCNN(num_classes=num_classes, in_channels=1)\n",
    "    \n",
    "#     # Print model summary\n",
    "#     print_model_summary(model)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightweightMedicalCNN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=1):\n",
    "        super(LightweightMedicalCNN, self).__init__()\n",
    "        \n",
    "        # Depthwise separable convolutional block\n",
    "        def depthwise_separable_conv(in_ch, out_ch, kernel_size=3, stride=1, padding=1):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, in_ch, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_ch),\n",
    "                nn.BatchNorm2d(in_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        # First block\n",
    "        self.conv1 = depthwise_separable_conv(in_channels, 32)\n",
    "        \n",
    "        # Second block with SE block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            depthwise_separable_conv(32, 48),\n",
    "            self.SEBlock(48)\n",
    "        )\n",
    "        \n",
    "        # Third block with SE block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            depthwise_separable_conv(48, 96),\n",
    "            self.SEBlock(96)\n",
    "        )\n",
    "        \n",
    "        # Spatial attention for focused spatial learning\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(96, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Capsule-inspired layer for feature extraction\n",
    "        self.caps_layer = nn.Sequential(\n",
    "            nn.Conv2d(96, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4, 4))\n",
    "        )\n",
    "        \n",
    "        # Flatten layer size calculation\n",
    "        self._to_linear = 16 * 4 * 4\n",
    "        \n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self._to_linear, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    # Squeeze-and-Excitation block\n",
    "    class SEBlock(nn.Module):\n",
    "        def __init__(self, channel, reduction=8):\n",
    "            super().__init__()\n",
    "            self.fc1 = nn.Linear(channel, channel // reduction)\n",
    "            self.fc2 = nn.Linear(channel // reduction, channel)\n",
    "\n",
    "        def forward(self, x):\n",
    "            b, c, _, _ = x.size()\n",
    "            y = torch.mean(x, dim=(2, 3))  # Global average pooling\n",
    "            y = F.relu(self.fc1(y))\n",
    "            y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n",
    "            return x * y.expand_as(x)\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Second block\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # Third block\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Apply spatial attention\n",
    "        attention = self.spatial_attention(x)\n",
    "        x = x * attention\n",
    "        \n",
    "        # Capsule-inspired feature extraction\n",
    "        x = self.caps_layer(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def print_model_summary(model, input_size=(1, 512, 512)):\n",
    "    \"\"\"\n",
    "    Print model summary and calculate model size\n",
    "    \"\"\"\n",
    "    batch_size = 1\n",
    "    input_shape = (batch_size, *input_size)\n",
    "    dummy_input = torch.randn(input_shape)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    model_size_mb = total_params * 4 / (1024 * 1024)  # 4 bytes per param\n",
    "\n",
    "    print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"Estimated Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    try:\n",
    "        output = model(dummy_input)\n",
    "        print(f\"Output Shape: {output.shape}\")\n",
    "        print(\"\\nModel summary test passed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during forward pass: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "def test_model(num_classes=5):\n",
    "    model = LightweightMedicalCNN(num_classes=num_classes, in_channels=1)\n",
    "    print_model_summary(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Test with 5 classes\n",
    "    model = test_model(num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "import wandb\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, transform=None):\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(1)  # Add channel dimension\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    device: str = None,\n",
    "    save_path: str = None\n",
    "):\n",
    "    \"\"\"Evaluate model on test set and generate detailed metrics\"\"\"\n",
    "    device = device or torch.device(\"cuda\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc='Testing'):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(all_targets, all_preds, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Test Set Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    if save_path:\n",
    "        # Save results\n",
    "        plt.savefig(os.path.join(save_path, 'confusion_matrix.png'))\n",
    "        report_df.to_csv(os.path.join(save_path, 'classification_report.csv'))\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report_df)\n",
    "    \n",
    "    return report_df, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_val):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = current_val\n",
    "        elif current_val > self.best_loss + self.min_delta and self.mode == 'min':\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = current_val\n",
    "            self.counter = 0\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        config: Dict,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        criterion: nn.Module = None,\n",
    "        optimizer: optim.Optimizer = None,\n",
    "        scheduler = None,\n",
    "        device: str = None\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion or nn.CrossEntropyLoss()\n",
    "        self.optimizer = optimizer or optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "        self.scheduler = scheduler or optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', patience=3, factor=0.1\n",
    "        )\n",
    "        self.device = device or torch.device(\"cuda\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.scaler = GradScaler('cuda')\n",
    "        self.early_stopping = EarlyStopping(patience=config['early_stopping_patience'])\n",
    "        \n",
    "        # Initialize metrics tracking\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_acc = 0.0\n",
    "        \n",
    "        # Setup WandB\n",
    "        self.run = wandb.init(\n",
    "            project=config['project_name'],\n",
    "            config=config,\n",
    "            name=f\"{config['model_name']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        )\n",
    "        \n",
    "        # Save paths\n",
    "        self.save_dir = config['save_dir']\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "    def train_epoch(self) -> Tuple[float, float]:\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Mixed precision training\n",
    "            with autocast('cuda'):\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            # Metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss/(batch_idx+1),\n",
    "                'acc': 100.*correct/total\n",
    "            })\n",
    "            \n",
    "        epoch_loss = running_loss / len(self.train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate_epoch(self) -> Tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc='Validation')\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'loss': running_loss/(batch_idx+1),\n",
    "                    'acc': 100.*correct/total\n",
    "                })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.val_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        # Log confusion matrix to WandB\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "        plt.figure(figsize=(10,8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Validation Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "        plt.close()\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self, epochs: int):\n",
    "        for epoch in range(epochs):\n",
    "            print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "            \n",
    "            # Training phase\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # Validation phase\n",
    "            val_loss, val_acc = self.validate_epoch()\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Logging\n",
    "            wandb.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"learning_rate\": current_lr\n",
    "            })\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.save_model('best_model.pth')\n",
    "            \n",
    "            # Early stopping check\n",
    "            self.early_stopping(val_loss)\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "        \n",
    "        # Save final model\n",
    "        self.save_model('final_model.pth')\n",
    "        self.run.finish()\n",
    "    \n",
    "    def save_model(self, filename: str):\n",
    "        \"\"\"Save model with config and metrics\"\"\"\n",
    "        save_path = os.path.join(self.save_dir, filename)\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'best_val_acc': self.best_val_acc,\n",
    "            'best_val_loss': self.best_val_loss\n",
    "        }, save_path)\n",
    "        wandb.save(save_path)\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'project_name': 'image_classification',\n",
    "        'model_name': 'EnhancedXRayClassifier',\n",
    "        'learning_rate': 0.00005,\n",
    "        'weight_decay': 1e-4,\n",
    "        'batch_size': 4,\n",
    "        'early_stopping_patience': 10,\n",
    "        'save_dir': './models',\n",
    "        'num_epochs': 100\n",
    "    }\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    val_dataset = CustomDataset(X_val, y_val)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    model = LightweightMedicalCNN(num_classes=5)  # Your model class\n",
    "    class_weights = [1 / count for count in label_list]\n",
    "    class_weights = torch.FloatTensor(class_weights)\n",
    "    device = torch.device(\"cuda\")\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        config=config,\n",
    "        criterion=criterion,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    trainer.train(epochs=config['num_epochs'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.clear_autocast_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and loader\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "model = LightweightMedicalCNN(num_classes=5)\n",
    "# Load best model\n",
    "checkpoint = torch.load('./models/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Evaluate\n",
    "report_df, confusion_matrix = evaluate_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    save_path='./results'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
