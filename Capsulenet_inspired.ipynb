{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "        self.original_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    def equalize_histogram(self):\n",
    "        self.equalized_img = cv2.equalizeHist(self.original_img)\n",
    "        return self.equalized_img\n",
    "\n",
    "    def normalize_image(self, image):\n",
    "        normalized_img = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "        return normalized_img\n",
    "\n",
    "    def resize_image(self, image, target_size):\n",
    "        resized_img = np.array(Image.fromarray((image * 255).astype(np.uint8)).resize(target_size))\n",
    "        return resized_img\n",
    "\n",
    "    def process_and_display(self):\n",
    "        # Perform all preprocessing steps\n",
    "        equalized_img = self.equalize_histogram()\n",
    "        normalized_img = self.normalize_image(equalized_img)\n",
    "        resized_img = self.resize_image(normalized_img, (256, 256))\n",
    "\n",
    "        # Plot the images with headings\n",
    "        images = [self.original_img, equalized_img, normalized_img, resized_img]\n",
    "        titles = ['Original Image', 'Equalized Histogram', 'Normalized Image', 'Resized Image']\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        for i, (img, title) in enumerate(zip(images, titles)):\n",
    "            plt.subplot(1, 4, i + 1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(title)\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        return resized_img\n",
    "\n",
    "# Usage\n",
    "image_path = 'DATASETS/split_data/train/2/9873823L.png'\n",
    "preprocessor = ImagePreprocessor(image_path)\n",
    "final_image = preprocessor.process_and_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def process_dataset(dataset_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Count total files for progress bar\n",
    "    total_files = sum(len(files) for _, _, files in os.walk(dataset_dir))\n",
    "\n",
    "    with tqdm(total=total_files, unit=\"images\", desc=\"Preprocessing dataset\") as pbar:\n",
    "        for dirname, _, filenames in os.walk(dataset_dir):\n",
    "            \n",
    "            # Check if directory name is numeric, indicating a label folder\n",
    "            if os.path.basename(dirname).isdigit():\n",
    "                label = int(os.path.basename(dirname))  # Folder name as the label\n",
    "\n",
    "                for filename in filenames:\n",
    "                    image_path = os.path.join(dirname, filename)\n",
    "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                    # Initialize preprocessor with the image path\n",
    "                    preprocessor = ImagePreprocessor(image_path)\n",
    "                    equalized_image = preprocessor.equalize_histogram()\n",
    "                    normalized_image = preprocessor.normalize_image(equalized_image)\n",
    "                    resized_image = preprocessor.resize_image(normalized_image, (256, 256))\n",
    "\n",
    "                    X.append(resized_image)\n",
    "                    y.append(label)\n",
    "\n",
    "                    pbar.update(1)\n",
    "        # Convert lists to NumPy arrays first\n",
    "        X_array = np.array(X)  # Convert to NumPy array\n",
    "        y_array = np.array(y)\n",
    "        # Convert lists to PyTorch tensors\n",
    "        X_tensor = torch.tensor(X_array).float()  # Convert to float tensor\n",
    "        y_tensor = torch.tensor(y_array).long()   # Convert to long tensor for labels\n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "# Usage\n",
    "dataset_dir = \"DATASETS/split_data/train/\"\n",
    "X_train, y_train = process_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"DATASETS/OSAIL_KL_Dataset/Labeled/\"\n",
    "X_val, y_val = process_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"DATASETS/split_data/test/\"\n",
    "X_test, y_test = process_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot random images with labels to check preprocessing\n",
    "num_samples = 5\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(num_samples):\n",
    "    idx = np.random.randint(0, len(X_train))\n",
    "    plt.subplot(1, num_samples, i + 1)\n",
    "    plt.imshow(X_train[idx], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array\n",
    "y_train_np = y_train.numpy()\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = collections.Counter(y_train_np)\n",
    "\n",
    "# Print the label distribution\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class SquashFunction(nn.Module):\n",
    "    def forward(self, x, dim=-1):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / torch.sqrt(squared_norm + 1e-8)\n",
    "\n",
    "class PrimaryCapsules(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dim_caps, kernel_size, stride):\n",
    "        super(PrimaryCapsules, self).__init__()\n",
    "        self.dim_caps = dim_caps\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * dim_caps, kernel_size, stride, padding=1)  # Added padding=1\n",
    "        self.squash = SquashFunction()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.conv(x)\n",
    "        batch, _, height, width = outputs.shape\n",
    "        \n",
    "        outputs = outputs.view(batch, self.out_channels, self.dim_caps, height, width)\n",
    "        outputs = outputs.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        outputs = outputs.view(batch, -1, self.dim_caps)\n",
    "        \n",
    "        return self.squash(outputs)\n",
    "\n",
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_caps_in, num_caps_out, dim_caps_in, dim_caps_out, num_iterations=3):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_caps_in = num_caps_in\n",
    "        self.num_caps_out = num_caps_out\n",
    "        \n",
    "        self.W = nn.Parameter(torch.randn(1, num_caps_in, num_caps_out, dim_caps_out, dim_caps_in))\n",
    "        self.squash = SquashFunction()\n",
    "\n",
    "    def forward(self, u):\n",
    "        batch_size = u.size(0)\n",
    "        u = u.unsqueeze(2).unsqueeze(4)\n",
    "        u_hat = torch.matmul(self.W, u)\n",
    "        u_hat = u_hat.squeeze(-1)\n",
    "        \n",
    "        b = torch.zeros(batch_size, self.num_caps_in, self.num_caps_out).to(u.device)\n",
    "        \n",
    "        for i in range(self.num_iterations):\n",
    "            c = F.softmax(b, dim=2)\n",
    "            c = c.unsqueeze(3)\n",
    "            s = (c * u_hat).sum(dim=1)\n",
    "            v = self.squash(s)\n",
    "            if i < self.num_iterations - 1:\n",
    "                b = b + (u_hat * v.unsqueeze(1)).sum(dim=-1)\n",
    "        \n",
    "        return v\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_layers, growth_rate=12):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            layer = nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels + i * growth_rate),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels + i * growth_rate, growth_rate, kernel_size=3, padding=1),\n",
    "                nn.Dropout(0.2)\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            new_features = layer(torch.cat(features, 1))\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "class EnhancedMedicalCapsCNN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=1):\n",
    "        super(EnhancedMedicalCapsCNN, self).__init__()\n",
    "        \n",
    "        # Initial feature extraction (256x256 -> 64x64)\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Multi-scale feature extraction (64x64 -> 64x64)\n",
    "        self.multi_scale = nn.ModuleList([\n",
    "            nn.Conv2d(32, 16, kernel_size=k, padding=k//2) \n",
    "            for k in [3, 5, 7]\n",
    "        ])\n",
    "        \n",
    "        # Dense block (64x64 -> 64x64)\n",
    "        self.dense_block = DenseBlock(48, num_layers=4, growth_rate=12)\n",
    "        dense_out_channels = 48 + 4 * 12  # 96 channels\n",
    "        \n",
    "        # Transition layer (64x64 -> 32x32)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.BatchNorm2d(dense_out_channels),\n",
    "            nn.Conv2d(dense_out_channels, dense_out_channels // 2, kernel_size=1),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        transition_out_channels = dense_out_channels // 2  # 48 channels\n",
    "        \n",
    "        # Primary capsules (32x32 -> 16x16 with padding=1)\n",
    "        self.primary_caps = PrimaryCapsules(\n",
    "            in_channels=transition_out_channels,\n",
    "            out_channels=32,\n",
    "            dim_caps=8,\n",
    "            kernel_size=3,\n",
    "            stride=2\n",
    "        )\n",
    "        \n",
    "        # Calculate primary capsules output size\n",
    "        # After PrimaryCapsules: 16x16 feature maps with 32 channels\n",
    "        # Total capsules = 32 * 16 * 16 = 8192\n",
    "        primary_caps_size = 32 * 16 * 16  # 8192\n",
    "        \n",
    "        # Medical feature capsules\n",
    "        self.medical_caps = CapsuleLayer(\n",
    "            num_caps_in=primary_caps_size,\n",
    "            num_caps_out=16,\n",
    "            dim_caps_in=8,\n",
    "            dim_caps_out=16\n",
    "        )\n",
    "        \n",
    "        # Diagnostic capsules\n",
    "        self.diagnostic_caps = CapsuleLayer(\n",
    "            num_caps_in=16,\n",
    "            num_caps_out=num_classes,\n",
    "            dim_caps_in=16,\n",
    "            dim_caps_out=16\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(48, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_classes * 16, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial feature extraction (256x256 -> 64x64)\n",
    "        x = self.init_conv(x)  # Output: [batch, 32, 64, 64]\n",
    "        \n",
    "        # Multi-scale feature extraction\n",
    "        multi_scale_features = [conv(x) for conv in self.multi_scale]\n",
    "        x = torch.cat(multi_scale_features, dim=1)  # Output: [batch, 48, 64, 64]\n",
    "        \n",
    "        # Apply attention\n",
    "        attention = self.attention(x)\n",
    "        x = x * attention\n",
    "        \n",
    "        # Dense feature extraction with transition (64x64 -> 32x32)\n",
    "        x = self.dense_block(x)  # Output: [batch, 96, 64, 64]\n",
    "        x = self.transition(x)   # Output: [batch, 48, 32, 32]\n",
    "        \n",
    "        # Primary capsules (32x32 -> 16x16)\n",
    "        primary_caps = self.primary_caps(x)  # Output: [batch, 8192, 8]\n",
    "        \n",
    "        # Medical feature capsules\n",
    "        medical_caps = self.medical_caps(primary_caps)  # Output: [batch, 16, 16]\n",
    "        \n",
    "        # Diagnostic capsules\n",
    "        diagnostic_caps = self.diagnostic_caps(medical_caps)  # Output: [batch, num_classes, 16]\n",
    "        \n",
    "        # Final classification\n",
    "        x = diagnostic_caps.view(diagnostic_caps.size(0), -1)\n",
    "        output = self.classifier(x)\n",
    "        \n",
    "        if self.training:\n",
    "            return output, diagnostic_caps\n",
    "        return output\n",
    "\n",
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, m_pos=0.9, m_neg=0.1, lambda_=0.5):\n",
    "        super(MarginLoss, self).__init__()\n",
    "        self.m_pos = m_pos\n",
    "        self.m_neg = m_neg\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, caps_output, target):\n",
    "        batch_size = caps_output.size(0)\n",
    "        \n",
    "        # Calculate vector length (magnitude) of capsule outputs\n",
    "        v_c = torch.sqrt((caps_output ** 2).sum(dim=-1))\n",
    "        \n",
    "        # Calculate losses for present and absent digit classes\n",
    "        left = F.relu(self.m_pos - v_c) ** 2\n",
    "        right = F.relu(v_c - self.m_neg) ** 2\n",
    "        \n",
    "        # Convert target to one-hot encoding\n",
    "        target = F.one_hot(target, num_classes=caps_output.size(1)).float()\n",
    "        \n",
    "        # Calculate total loss\n",
    "        loss = target * left + self.lambda_ * (1.0 - target) * right\n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "\n",
    "def print_model_summary(model, input_size=(1, 256, 256)):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    batch_size = 1\n",
    "    input_shape = (batch_size, *input_size)\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(model)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "    \n",
    "    model_size_mb = total_params * 4 / (1024 * 1024)\n",
    "    print(f\"Estimated Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    try:\n",
    "        output = model(dummy_input)\n",
    "        print(f\"\\nInput Shape: {input_shape}\")\n",
    "        if isinstance(output, tuple):\n",
    "            print(f\"Output Shapes: {[o.shape for o in output]}\")\n",
    "        else:\n",
    "            print(f\"Output Shape: {output.shape}\")\n",
    "        print(\"\\nModel summary test passed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during forward pass: {str(e)}\")\n",
    "\n",
    "def test_model(num_classes=5):\n",
    "    model = EnhancedMedicalCapsCNN(num_classes=num_classes)\n",
    "    print_model_summary(model)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = test_model(num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "import wandb\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, transform=None):\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(1)  # Add channel dimension\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_val):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = current_val\n",
    "        elif current_val > self.best_loss + self.min_delta and self.mode == 'min':\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = current_val\n",
    "            self.counter = 0\n",
    "class MedicalCapsTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        config: Dict,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        margin_loss_params: Dict = None,\n",
    "        optimizer: optim.Optimizer = None,\n",
    "        scheduler = None,\n",
    "        device: str = None\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        \n",
    "        # Initialize MarginLoss with default or custom parameters\n",
    "        margin_loss_params = margin_loss_params or {\n",
    "            'm_pos': 0.9,\n",
    "            'm_neg': 0.1,\n",
    "            'lambda_': 0.5\n",
    "        }\n",
    "        self.criterion = MarginLoss(**margin_loss_params)\n",
    "        \n",
    "        self.optimizer = optimizer or optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "        self.scheduler = scheduler or optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', patience=3, factor=0.1\n",
    "        )\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.scaler = GradScaler()\n",
    "        self.early_stopping = EarlyStopping(patience=config['early_stopping_patience'])\n",
    "        \n",
    "        # Initialize metrics tracking\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_acc = 0.0\n",
    "        \n",
    "        # Setup WandB\n",
    "        self.run = wandb.init(\n",
    "            project=config['project_name'],\n",
    "            config=config,\n",
    "            name=f\"{config['model_name']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            mode=config.get('wandb_mode', 'online')\n",
    "        )\n",
    "        \n",
    "        # Save paths\n",
    "        self.save_dir = config['save_dir']\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "    \n",
    "    def train_epoch(self) -> Tuple[float, float]:\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Mixed precision training\n",
    "            with autocast('cuda'):\n",
    "                outputs = self.model(inputs)\n",
    "                if isinstance(outputs, tuple):\n",
    "                    logits, caps_output = outputs\n",
    "                else:\n",
    "                    logits = outputs\n",
    "                    caps_output = None\n",
    "                \n",
    "                # If we have capsule output, use it for the loss\n",
    "                if caps_output is not None:\n",
    "                    loss = self.criterion(caps_output, targets)\n",
    "                    class_outputs = torch.sqrt((caps_output ** 2).sum(dim=-1))\n",
    "                else:\n",
    "                    loss = F.cross_entropy(logits, targets)\n",
    "                    class_outputs = logits\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            # Metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = class_outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss/(batch_idx+1),\n",
    "                'acc': 100.*correct/total\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate_epoch(self) -> Tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc='Validation')\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                if isinstance(outputs, tuple):\n",
    "                    logits, caps_output = outputs\n",
    "                else:\n",
    "                    logits = outputs\n",
    "                    caps_output = None\n",
    "                \n",
    "                # If we have capsule output, use it for the loss\n",
    "                if caps_output is not None:\n",
    "                    loss = self.criterion(caps_output, targets)\n",
    "                    class_outputs = torch.sqrt((caps_output ** 2).sum(dim=-1))\n",
    "                else:\n",
    "                    loss = F.cross_entropy(logits, targets)\n",
    "                    class_outputs = logits\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = class_outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                \n",
    "                pbar.set_postfix({\n",
    "                    'loss': running_loss/(batch_idx+1),\n",
    "                    'acc': 100.*correct/total\n",
    "                })\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.val_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        # Log confusion matrix\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "        plt.figure(figsize=(10,8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Validation Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "        plt.close()\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self, epochs: int):\n",
    "        for epoch in range(epochs):\n",
    "            print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "            \n",
    "            # Training phase\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # Validation phase\n",
    "            val_loss, val_acc = self.validate_epoch()\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Logging\n",
    "            wandb.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"learning_rate\": current_lr\n",
    "            })\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.save_model('best_model.pth')\n",
    "            \n",
    "            # Early stopping check\n",
    "            self.early_stopping(val_loss)\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "        \n",
    "        # Save final model\n",
    "        self.save_model('final_model.pth')\n",
    "        self.run.finish()\n",
    "    \n",
    "    def save_model(self, filename: str):\n",
    "        \"\"\"Save model with config and metrics\"\"\"\n",
    "        save_path = os.path.join(self.save_dir, filename)\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'best_val_acc': self.best_val_acc,\n",
    "            'best_val_loss': self.best_val_loss\n",
    "        }, save_path)\n",
    "        wandb.save(save_path)\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'project_name': 'medical_capsule_classification',\n",
    "        'model_name': 'EnhancedMedicalCapsCNN',\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'batch_size': 16,\n",
    "        'early_stopping_patience': 10,\n",
    "        'save_dir': './models',\n",
    "        'num_epochs': 100\n",
    "    }\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    val_dataset = CustomDataset(X_val, y_val)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    model = EnhancedMedicalCapsCNN(num_classes=len(np.unique(y_train)))\n",
    "    trainer = MedicalCapsTrainer(\n",
    "        model=model,\n",
    "        config=config,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    trainer.train(epochs=config['num_epochs'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    device: str = None,\n",
    "    save_path: str = None,\n",
    "    class_names: List[str] = None\n",
    ") -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Evaluate capsule network model on test set and generate detailed metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: The capsule network model\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Computing device (cuda/cpu)\n",
    "        save_path: Path to save evaluation results\n",
    "        class_names: List of class names for better visualization\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (classification report DataFrame, confusion matrix)\n",
    "    \"\"\"\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc='Testing'):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Get model outputs\n",
    "            outputs, caps_output = model(inputs)\n",
    "            \n",
    "            # Calculate capsule magnitudes for classification\n",
    "            class_outputs = torch.sqrt((caps_output ** 2).sum(dim=-1))\n",
    "            probs = F.softmax(class_outputs, dim=1)\n",
    "            \n",
    "            _, predicted = class_outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(\n",
    "        all_targets, \n",
    "        all_preds, \n",
    "        output_dict=True,\n",
    "        target_names=class_names if class_names else None\n",
    "    )\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Calculate and add additional metrics\n",
    "    report_df['balanced_accuracy'] = balanced_accuracy_score(all_targets, all_preds)\n",
    "    report_df['roc_auc'] = calculate_multiclass_roc_auc(all_targets, all_probs)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    \n",
    "    # Normalize confusion matrix for percentage view\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Create confusion matrix plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Raw counts\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "    ax1.set_title('Test Set Confusion Matrix (Counts)')\n",
    "    ax1.set_ylabel('True Label')\n",
    "    ax1.set_xlabel('Predicted Label')\n",
    "    if class_names:\n",
    "        ax1.set_xticklabels(class_names, rotation=45)\n",
    "        ax1.set_yticklabels(class_names, rotation=45)\n",
    "    \n",
    "    # Normalized percentages\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', ax=ax2)\n",
    "    ax2.set_title('Test Set Confusion Matrix (Normalized)')\n",
    "    ax2.set_ylabel('True Label')\n",
    "    ax2.set_xlabel('Predicted Label')\n",
    "    if class_names:\n",
    "        ax2.set_xticklabels(class_names, rotation=45)\n",
    "        ax2.set_yticklabels(class_names, rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Save results\n",
    "        plt.savefig(os.path.join(save_path, 'confusion_matrices.png'))\n",
    "        report_df.to_csv(os.path.join(save_path, 'classification_report.csv'))\n",
    "        \n",
    "        # Save ROC curves\n",
    "        plot_roc_curves(all_targets, all_probs, class_names)\n",
    "        plt.savefig(os.path.join(save_path, 'roc_curves.png'))\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report_df)\n",
    "    \n",
    "    return report_df, cm\n",
    "\n",
    "def calculate_multiclass_roc_auc(y_true, y_prob):\n",
    "    \"\"\"Calculate ROC AUC for multiclass classification\"\"\"\n",
    "    if y_prob.shape[1] == 2:\n",
    "        return roc_auc_score(y_true, y_prob[:, 1])\n",
    "    else:\n",
    "        return roc_auc_score(y_true, y_prob, multi_class='ovr')\n",
    "\n",
    "def plot_roc_curves(y_true, y_prob, class_names=None):\n",
    "    \"\"\"Plot ROC curves for each class\"\"\"\n",
    "    n_classes = y_prob.shape[1]\n",
    "    \n",
    "    # Create class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f'Class {i}' for i in range(n_classes)]\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot for each class\n",
    "    for i in range(n_classes):\n",
    "        # Convert to binary classification problem\n",
    "        y_true_binary = (y_true == i).astype(int)\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_true_binary, y_prob[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.plot(\n",
    "            fpr, \n",
    "            tpr, \n",
    "            label=f'{class_names[i]} (AUC = {roc_auc:.2f})'\n",
    "        )\n",
    "    \n",
    "    # Plot diagonal line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    \n",
    "    # Set plot properties\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and loader\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "model = EnhancedMedicalCapsCNN(num_classes=5)\n",
    "# Load best model\n",
    "checkpoint = torch.load('./models/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate\n",
    "report_df, confusion_matrix = evaluate_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    save_path='./results'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
